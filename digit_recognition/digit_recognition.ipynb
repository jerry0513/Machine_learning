{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ed3014c62fae>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct as struct\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import math\n",
    "import scipy.ndimage\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#Load mnist\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.9155\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "a placeholder for our image data:\n",
    "None stands for an unspecified number of images\n",
    "784 = 28*28 pixel\n",
    "\"\"\"\n",
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "\n",
    "# we need our weights for our neural net\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "# and the biases\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\"\"\"\n",
    "softmax provides a probability based output\n",
    "we need to multiply the image values x and the weights\n",
    "and add the biases\n",
    "(the normal procedure, explained in previous articles)\n",
    "\"\"\"\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "\"\"\"\n",
    "y_ will be filled with the real values\n",
    "which we want to train (digits 0-9)\n",
    "for an undefined number of images\n",
    "\"\"\"\n",
    "y_ = tf.placeholder(\"float\", [None,10])\n",
    "\n",
    "\"\"\"\n",
    "we use the cross_entropy function\n",
    "which we want to minimize to improve our model\n",
    "\"\"\"\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "\"\"\"\n",
    "use a learning rate of 0.01\n",
    "to minimize the cross_entropy error\n",
    "\"\"\"\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# initialize all variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# create a session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# use 1000 batches with a size of 100 each to train our net\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  # run the train_step function with the given image values (x) and the real output (y_)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "\"\"\"\n",
    "Let's get the accuracy of our model:\n",
    "our model is correct if the index with the highest y value\n",
    "is the same as in the real digit vector\n",
    "The mean of the correct_prediction gives us the accuracy.\n",
    "We need to run the accuracy function\n",
    "with our test set (mnist.test)\n",
    "We use the keys \"images\" and \"labels\" for x and y_\n",
    "\"\"\"\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print (sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def getBestShift(img):\n",
    "    cy,cx = scipy.ndimage.measurements.center_of_mass(img)\n",
    "\n",
    "    rows,cols = img.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "\n",
    "    return shiftx,shifty\n",
    "\n",
    "def shift(img,sx,sy):\n",
    "    rows,cols = img.shape\n",
    "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return shifted\n",
    "\n",
    "# create an array where we can store our 4 pictures\n",
    "images = np.zeros((1,784))\n",
    "# and the correct values\n",
    "correct_vals = np.zeros((1,10))\n",
    "\n",
    "# we want to test our images which you saw at the top of this page\n",
    "i = 0\n",
    "for no in [3]:\n",
    "    # read the image\n",
    "    gray = cv2.imread(\"00.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "#     # resize the images and invert it (black background)\n",
    "#     gray = cv2.resize(255-gray, (28, 28))\n",
    "#     (thresh, gray) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#     while np.sum(gray[0]) == 0:\n",
    "#         gray = gray[1:]\n",
    "\n",
    "#     while np.sum(gray[:,0]) == 0:\n",
    "#         gray = np.delete(gray,0,1)\n",
    "\n",
    "#     while np.sum(gray[-1]) == 0:\n",
    "#         gray = gray[:-1]\n",
    "\n",
    "#     while np.sum(gray[:,-1]) == 0:\n",
    "#         gray = np.delete(gray,-1,1)\n",
    "\n",
    "#     rows,cols = gray.shape\n",
    "    \n",
    "#     if rows > cols:\n",
    "#         factor = 20.0/rows\n",
    "#         rows = 20\n",
    "#         cols = int(round(cols*factor))\n",
    "#         gray = cv2.resize(gray, (cols,rows))\n",
    "#     else:\n",
    "#         factor = 20.0/cols\n",
    "#         cols = 20\n",
    "#         rows = int(round(rows*factor))\n",
    "#         gray = cv2.resize(gray, (cols, rows))\n",
    "\n",
    "#     colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "#     rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "#     gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "#     shiftx,shifty = getBestShift(gray)\n",
    "#     shifted = shift(gray,shiftx,shifty)\n",
    "#     gray = shifted\n",
    "    \n",
    "    # save the processed images\n",
    "    cv2.imwrite(\"images/00.jpg\", gray)\n",
    "    \"\"\"\n",
    "    all images in the training set have an range from 0-1\n",
    "    and not from 0-255 so we divide our flatten images\n",
    "    (a one dimensional vector with our 784 pixels)\n",
    "    to use the same 0-1 based range\n",
    "    \"\"\"\n",
    "    flatten = gray.flatten() / 255.0\n",
    "    \"\"\"\n",
    "    we need to store the flatten image and generate\n",
    "    the correct_vals array\n",
    "    correct_val for the first digit (9) would be\n",
    "    [0,0,0,0,0,0,0,0,0,1]\n",
    "    \"\"\"\n",
    "    images[i] = flatten\n",
    "    correct_val = np.zeros((10))\n",
    "    correct_val[no] = 1\n",
    "    correct_vals[i] = correct_val\n",
    "    i += 1\n",
    "\n",
    "\"\"\"\n",
    "the prediction will be an array with four values,\n",
    "which show the predicted number\n",
    "\"\"\"\n",
    "prediction = tf.argmax(y,1)\n",
    "\"\"\"\n",
    "we want to run the prediction and the accuracy function\n",
    "using our generated arrays (images and correct_vals)\n",
    "\"\"\"\n",
    "print (sess.run(prediction, feed_dict={x: np.reshape(images, (1,-1)), y_: correct_vals}))\n",
    "print (sess.run(accuracy, feed_dict={x: np.reshape(images, (1,-1)), y_: correct_vals}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
